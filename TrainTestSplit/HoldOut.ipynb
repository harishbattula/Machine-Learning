{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "1a111461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For creating random arrays and performing numeriacl computaions on multidimensional arrays\n",
    "import numpy as np\n",
    "\n",
    "# To view multidimensional array in dataframe format\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "82eda109",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.91153695, 0.74896568, 0.55172731, ..., 0.69124928, 0.71237749,\n",
       "        0.26466663],\n",
       "       [0.90345003, 0.62656029, 0.161987  , ..., 0.23525497, 0.23022878,\n",
       "        0.24847568],\n",
       "       [0.32503713, 0.92074913, 0.82782639, ..., 0.84472987, 0.31730537,\n",
       "        0.52223294],\n",
       "       ...,\n",
       "       [0.72527784, 0.42560411, 0.54217385, ..., 0.77551069, 0.3155721 ,\n",
       "        0.56382826],\n",
       "       [0.99051797, 0.52477399, 0.32687042, ..., 0.13255607, 0.03791067,\n",
       "        0.0421957 ],\n",
       "       [0.34602463, 0.27675626, 0.95691605, ..., 0.54504555, 0.55575379,\n",
       "        0.64034364]])"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "NoofFeatures = 8\n",
    "NoofSamples = 150\n",
    "data = np.random.rand(NoofSamples, NoofFeatures)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "47d00ebb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = np.random.choice([0, 1], NoofSamples).reshape(-1, 1)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "8d66aa97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.91153695, 0.74896568, 0.55172731, ..., 0.71237749, 0.26466663,\n",
       "        1.        ],\n",
       "       [0.90345003, 0.62656029, 0.161987  , ..., 0.23022878, 0.24847568,\n",
       "        1.        ],\n",
       "       [0.32503713, 0.92074913, 0.82782639, ..., 0.31730537, 0.52223294,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.72527784, 0.42560411, 0.54217385, ..., 0.3155721 , 0.56382826,\n",
       "        0.        ],\n",
       "       [0.99051797, 0.52477399, 0.32687042, ..., 0.03791067, 0.0421957 ,\n",
       "        1.        ],\n",
       "       [0.34602463, 0.27675626, 0.95691605, ..., 0.55575379, 0.64034364,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.hstack((data, labels))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "1074c788",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column1</th>\n",
       "      <th>column2</th>\n",
       "      <th>column3</th>\n",
       "      <th>column4</th>\n",
       "      <th>column5</th>\n",
       "      <th>column6</th>\n",
       "      <th>column7</th>\n",
       "      <th>column8</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.911537</td>\n",
       "      <td>0.748966</td>\n",
       "      <td>0.551727</td>\n",
       "      <td>0.210204</td>\n",
       "      <td>0.916817</td>\n",
       "      <td>0.691249</td>\n",
       "      <td>0.712377</td>\n",
       "      <td>0.264667</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.903450</td>\n",
       "      <td>0.626560</td>\n",
       "      <td>0.161987</td>\n",
       "      <td>0.772146</td>\n",
       "      <td>0.615695</td>\n",
       "      <td>0.235255</td>\n",
       "      <td>0.230229</td>\n",
       "      <td>0.248476</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.325037</td>\n",
       "      <td>0.920749</td>\n",
       "      <td>0.827826</td>\n",
       "      <td>0.076615</td>\n",
       "      <td>0.128831</td>\n",
       "      <td>0.844730</td>\n",
       "      <td>0.317305</td>\n",
       "      <td>0.522233</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.054053</td>\n",
       "      <td>0.071210</td>\n",
       "      <td>0.299820</td>\n",
       "      <td>0.126293</td>\n",
       "      <td>0.819635</td>\n",
       "      <td>0.164257</td>\n",
       "      <td>0.964131</td>\n",
       "      <td>0.375068</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.585186</td>\n",
       "      <td>0.798749</td>\n",
       "      <td>0.828683</td>\n",
       "      <td>0.603726</td>\n",
       "      <td>0.945621</td>\n",
       "      <td>0.158726</td>\n",
       "      <td>0.541716</td>\n",
       "      <td>0.971482</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>0.421247</td>\n",
       "      <td>0.833867</td>\n",
       "      <td>0.447115</td>\n",
       "      <td>0.673604</td>\n",
       "      <td>0.545643</td>\n",
       "      <td>0.183373</td>\n",
       "      <td>0.111910</td>\n",
       "      <td>0.818577</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>0.313534</td>\n",
       "      <td>0.491613</td>\n",
       "      <td>0.188965</td>\n",
       "      <td>0.190566</td>\n",
       "      <td>0.172941</td>\n",
       "      <td>0.737589</td>\n",
       "      <td>0.704118</td>\n",
       "      <td>0.261818</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>0.725278</td>\n",
       "      <td>0.425604</td>\n",
       "      <td>0.542174</td>\n",
       "      <td>0.259065</td>\n",
       "      <td>0.194146</td>\n",
       "      <td>0.775511</td>\n",
       "      <td>0.315572</td>\n",
       "      <td>0.563828</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>0.990518</td>\n",
       "      <td>0.524774</td>\n",
       "      <td>0.326870</td>\n",
       "      <td>0.469361</td>\n",
       "      <td>0.464787</td>\n",
       "      <td>0.132556</td>\n",
       "      <td>0.037911</td>\n",
       "      <td>0.042196</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>0.346025</td>\n",
       "      <td>0.276756</td>\n",
       "      <td>0.956916</td>\n",
       "      <td>0.268366</td>\n",
       "      <td>0.760525</td>\n",
       "      <td>0.545046</td>\n",
       "      <td>0.555754</td>\n",
       "      <td>0.640344</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      column1   column2   column3   column4   column5   column6   column7  \\\n",
       "0    0.911537  0.748966  0.551727  0.210204  0.916817  0.691249  0.712377   \n",
       "1    0.903450  0.626560  0.161987  0.772146  0.615695  0.235255  0.230229   \n",
       "2    0.325037  0.920749  0.827826  0.076615  0.128831  0.844730  0.317305   \n",
       "3    0.054053  0.071210  0.299820  0.126293  0.819635  0.164257  0.964131   \n",
       "4    0.585186  0.798749  0.828683  0.603726  0.945621  0.158726  0.541716   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "145  0.421247  0.833867  0.447115  0.673604  0.545643  0.183373  0.111910   \n",
       "146  0.313534  0.491613  0.188965  0.190566  0.172941  0.737589  0.704118   \n",
       "147  0.725278  0.425604  0.542174  0.259065  0.194146  0.775511  0.315572   \n",
       "148  0.990518  0.524774  0.326870  0.469361  0.464787  0.132556  0.037911   \n",
       "149  0.346025  0.276756  0.956916  0.268366  0.760525  0.545046  0.555754   \n",
       "\n",
       "      column8  Target  \n",
       "0    0.264667     1.0  \n",
       "1    0.248476     1.0  \n",
       "2    0.522233     0.0  \n",
       "3    0.375068     0.0  \n",
       "4    0.971482     0.0  \n",
       "..        ...     ...  \n",
       "145  0.818577     1.0  \n",
       "146  0.261818     1.0  \n",
       "147  0.563828     0.0  \n",
       "148  0.042196     1.0  \n",
       "149  0.640344     0.0  \n",
       "\n",
       "[150 rows x 9 columns]"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DataFrame = pd.DataFrame(data, columns = [\"column1\", \"column2\", \"column3\", \"column4\", \"column5\", \"column6\", \"column7\"\n",
    "                                         , \"column8\", \"Target\"])\n",
    "DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "36bed19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can't perform tests on train data itself\n",
    "# if we do that, then our model gets overfitted\n",
    "# means it performs well on already visited data, but predicts bad for unseen data\n",
    "# to tackle this we have different methods in model evalution\n",
    "\n",
    "# Different types of techniques in Model Evalution\n",
    "# Hold Out\n",
    "# Cross Validation\n",
    "\n",
    "# Hold Out\n",
    "\n",
    "# In hold out we devide dataset into three subsets\n",
    "# 1. Train Dataset\n",
    "# 2. Validation Dataset\n",
    "# 3. Test Dataset\n",
    "\n",
    "# Each dataset is subset of dataset, observations in each dataset are unique (if we done data preparaion properly)\n",
    "# In this method of model evalution, we train the model on train dataset(it may be 70%)\n",
    "# we do the validation process, to get best hyperparameters for the given dataset and model\n",
    "# Note all models may not this validation subset for model evalution (may be 15% if  needed)\n",
    "# We test the model on test dataset, to track feature performance of our model\n",
    "\n",
    "# Hold out model evalution using numpy\n",
    "\n",
    "TrianSplitPercentage = 70\n",
    "ValidationSplitPercentage = 15\n",
    "TestSplitPercentage = 15\n",
    "\n",
    "# First let us find percentage of positive's and negative's in our dataset\n",
    "NoofPositives = DataFrame[DataFrame[\"Target\"] == 1].shape[0]\n",
    "\n",
    "# We have 74 1's and 76 0's in out dataset\n",
    "ProbabilityOfPositivesInDF = NoofPositives/(NoofSamples)\n",
    "\n",
    "# We don't need to calculate probability for negatives\n",
    "# We can get it by positive probalbility from total probability(1)\n",
    "\n",
    "# NoofNegatives = DataFrame[DataFrame[\"Target\"] == 0].shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "3f6153a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can devide df into three subsets, without considering amount of negatives and positives in our dataset\n",
    "# If we do that, there are chances of getting all one's or zero's in any of three subsets\n",
    "# Or atleast there are chances of getting more zero's, less one's and viceversa\n",
    "\n",
    "# Therefore applying stratified way of splitting can become crucial in model performace\n",
    "# Below is the stratified way of spltting dataset using hold out model evalution method\n",
    "\n",
    "# np.random.shuffle(data)\n",
    "\n",
    "HoldOutTrainSampleSize = int((TrianSplitPercentage/100) * NoofSamples)\n",
    "HoldOutValSamplesSize = int((ValidationSplitPercentage/100) * NoofSamples)\n",
    "HoldOutTestSize = int((TestSplitPercentage/100) * NoofSamples)\n",
    "\n",
    "# print(HoldOutTrainSampleSize)\n",
    "# print(HoldOutValSamplesSize)\n",
    "# print(HoldOutTestSize)\n",
    "\n",
    "\n",
    "# Initilizing and declaring datasets as empty using np.empty\n",
    "\n",
    "HoldOutTrain = np.empty((HoldOutTrainSampleSize, NoofFeatures+1))\n",
    "HoldOutVal = np.empty((HoldOutValSamplesSize, NoofFeatures+1))\n",
    "HoldOutTest = np.empty((HoldOutTestSize, NoofFeatures+1))\n",
    "\n",
    "\n",
    "# Get correct split of positives and negatives, depending on one's and zero's probability in our dataset\n",
    "LabelsForHoldOutTrainSet = np.random.choice([1, 0], HoldOutTrainSampleSize, p = [ProbabilityOfPositivesInDF, 1 - ProbabilityOfPositivesInDF])\n",
    "\n",
    "# print(vals)\n",
    "\n",
    "for i in range(LabelsForHoldOutTrainSet.size):\n",
    "    \n",
    "    # To get first occurance of label, we use np.where\n",
    "    # but it returns all indexes with that the label specified\n",
    "    indexes = np.where(data[:, -1] == LabelsForHoldOutTrainSet[i])\n",
    "    \n",
    "    # So we get first occurance of label by using indexes[0][0] # means [first row][first column]\n",
    "    # since it is multidimensional array we use [0][0] instead of [0]\n",
    "    FirstOccurance = indexes[0][0]\n",
    "    \n",
    "    # Update values in HoldOutTrain that we declared as an empty array before\n",
    "    HoldOutTrain[i] =  data[index, :]\n",
    "    \n",
    "    # Now delete the sample in original dataframe\n",
    "    data = np.delete(data, index, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "3f3b3641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numpy array to DataFrame\n",
    "HoldOutTrainData = pd.DataFrame(HoldOutTrain, columns=[\"column1\", \"column2\", \"column3\", \"column4\", \"column5\", \"column6\", \"column7\"\n",
    "                                         , \"column8\", \"Target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "d406ed76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4888888888888889"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generating validation subset whose size is 15% of parent set\n",
    "\n",
    "# Find probabilities of positives and negatives in the remaining data\n",
    "DataFrame = pd.DataFrame(data, columns=[\"column1\", \"column2\", \"column3\", \"column4\", \"column5\", \"column6\", \"column7\"\n",
    "                                         , \"column8\", \"Target\"])\n",
    "\n",
    "ProbabilityOfPositives = DataFrame[DataFrame[\"Target\"] == 1].shape[0]/ DataFrame.shape[0]\n",
    "ProbabilityOfPositives\n",
    "\n",
    "# Negative's probability in latest dataset is 1 - ProbabilityOfPositives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "2f8fa5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get correct split of positives and negatives for hold out validation subset\n",
    "# depending on one's and zero's probability in remain dataset\n",
    "LabelsForHoldOutValSet = np.random.choice([1, 0], HoldOutValSamplesSize, \n",
    "                                          p = [ProbabilityOfPositives, 1 - ProbabilityOfPositives])\n",
    "\n",
    "\n",
    "for i in range(LabelsForHoldOutValSet.size):\n",
    "    \n",
    "    # getting indexes of DataFrame where target is current label\n",
    "    indexes = np.where(data[:, -1] == LabelsForHoldOutValSet[i])\n",
    "    \n",
    "    # Get first index from indexes\n",
    "    FirstOccurance = indexes[0][0]\n",
    "    \n",
    "    # Update values in HoldOutVal\n",
    "    HoldOutVal[i] = data[FirstOccurance, :]\n",
    "    \n",
    "    # Delete sample by index in data\n",
    "    data = np.delete(data, index, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "04e418f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dataframe for holdoutval set\n",
    "HoldOutValData = pd.DataFrame(HoldOutVal, columns = [\"column1\", \"column2\", \"column3\", \"column4\", \"column5\", \"column6\", \"column7\"\n",
    "                                         , \"column8\", \"Target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "f9a894a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remaining samples in data are actually test data\n",
    "# therefore we can consider this as test dataset\n",
    "HoldOutTestData = pd.DataFrame(data, columns = [\"column1\", \"column2\", \"column3\", \"column4\", \"column5\", \"column6\", \"column7\"\n",
    "                                         , \"column8\", \"Target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "1811e30e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Data\n",
      "No of Positive labels :  72\n",
      "No of Negative labels :  78\n",
      "Train Data\n",
      "No of Positive labels :  55\n",
      "No of Positive labels :  50\n",
      "Validation Data\n",
      "No of Positive labels :  12\n",
      "No of Negative labels :  10\n",
      "Test Data\n",
      "No of Positive labels :  14\n",
      "No of Positive labels :  9\n"
     ]
    }
   ],
   "source": [
    "# Let us view what we get from above traintest split procedure\n",
    "# TrainSet\n",
    "\n",
    "print(\"Actual Data\")\n",
    "print(\"No of Positive labels : \", NoofPositives)\n",
    "print(\"No of Negative labels : \", NoofSamples - NoofPositives)\n",
    "\n",
    "# No of positives in train data\n",
    "NoofPos = HoldOutTrainData[HoldOutTrainData[\"Target\"] == 0].shape[0]\n",
    "\n",
    "print(\"Train Data\")\n",
    "print(\"No of Positive labels : \",NoofPos)\n",
    "\n",
    "# No of negatives in train data\n",
    "print(\"No of Positive labels : \",HoldOutTrainData.shape[0] - NoofPos)\n",
    "\n",
    "# No of positives in Validation set\n",
    "NoofPos = HoldOutValData[HoldOutValData[\"Target\"] == 0].shape[0]\n",
    "\n",
    "print(\"Validation Data\")\n",
    "\n",
    "print(\"No of Positive labels : \",NoofPos)\n",
    "\n",
    "# No of negative labels in validation data\n",
    "print(\"No of Negative labels : \",HoldOutValData.shape[0] - NoofPos)\n",
    "\n",
    "print(\"Test Data\")\n",
    "\n",
    "# No of positives in Test set\n",
    "NoofPos = HoldOutTestData[HoldOutTestData[\"Target\"] == 0].shape[0]\n",
    "\n",
    "print(\"No of Positive labels : \",NoofPos)\n",
    "\n",
    "# No of negatives\n",
    "print(\"No of Positive labels : \",HoldOutTestData.shape[0] - NoofPos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "0e86506e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 1. 1. 1. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0.\n",
      " 0. 0. 1. 0. 1. 1. 0. 0. 0. 1. 1. 0. 1. 0. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1.\n",
      " 0. 0. 0. 1. 0. 1. 1. 1. 0. 0. 1. 1. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1.\n",
      " 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 1. 1. 0. 1. 0. 1. 0. 0.]\n",
      "[1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 1. 1. 0. 0. 1.]\n",
      "[0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0.]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(HoldOutTrainData.iloc[:, -1].values)\n",
    "print(HoldOutValData.iloc[:, -1].values)\n",
    "print(HoldOutTestData.iloc[:, -1].values, end = \"\\n\\n\")\n",
    "\n",
    "# It is stratified way of sampling, after splitting there same amount(a little bit vary) of \n",
    "# negatives and positives in each subset.\n",
    "# Will upload all cross validation techniques as a seperate file\n",
    "# let me know if any updates or errors or better way of doing(not sklearn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
